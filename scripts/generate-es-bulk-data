#!/usr/bin/python3
"""
From the collection metadata and extracted document text files, generate an
Elasticsearch Bulk API input file as described here:
https://www.elastic.co/guide/en/elasticsearch/reference/7.6/docs-bulk.html

"""

import argparse
import csv
import json
import os


collection_name_to_index_name = lambda s: '_'.join(s.lower().split(' '))


def main(metadata_fh, search_config_fh, text_path, output_fh):
    metadata_reader = csv.DictReader(metadata_fh)

    # Create a search config <fieldName> => <configDict> map.
    search_config_reader = csv.DictReader(search_config_fh)
    field_config_map = { x['field']: x for x in search_config_reader }

    num_items = 0
    for item in metadata_reader:
        filename = item['filename']

        # Remove any fields with an empty value.
        item = { k: v for k, v in item.items() if v }

        # Split each multi-valued field value into a list of values.
        for k, v in item.items():
            if (k in field_config_map
                and field_config_map[k]['multi-valued'] == "true"):
                item[k] = [s.strip() for s in v.split(';')]

        item_text_path = os.path.join(text_path, '{}.text'.format(filename))
        if os.path.exists(item_text_path):
            full_text = open(item_text_path, 'r', encoding='utf-8').read()
            item['full_text'] = full_text

        # Write the action_and_meta_data line.
        doc_id = item['objectid']
        index_name = collection_name_to_index_name(item['digital_collection'])
        output_fh.write(
            '{{"index": {{"_index": "{}", "_id": "{}"}}}}\n'
            .format(index_name, doc_id)
        )

        # Write the optional_source line.
        output_fh.write(u'{}\n'.format(json.dumps(item, separators=(',', ':'), ensure_ascii=False)))
        num_items += 1

    print('Wrote {} items to: {}'.format(num_items, output_fh.name))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('metadata_file', type=argparse.FileType('r'))
    parser.add_argument('search_config_file', type=argparse.FileType('r'))
    parser.add_argument('extracted_text_dir')
    parser.add_argument('output_file', type=argparse.FileType('w', encoding="utf-8"))
    args = parser.parse_args()

    main(args.metadata_file, args.search_config_file,
         args.extracted_text_dir, args.output_file)
