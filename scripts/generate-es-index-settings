#!/usr/bin/python3
"""
Generate a file that comprises the Analysis and Mapping settings for the
Elasticsearch index from the configuration specified in _data/config.search.yml

https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis.html
https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping.html
"""

import argparse
import csv
import json


TEXT_FIELD_DEF_KEYS = {'field'}
BOOL_FIELD_DEF_KEYS = {'index', 'display', 'facet', 'multi-valued'}
VALID_FIELD_DEF_KEYS = TEXT_FIELD_DEF_KEYS.union(BOOL_FIELD_DEF_KEYS)


analysis = {
    "analyzer": {
        "semicolon_delimited_analyzer": {
            "tokenizer": "semicolon_delimited_tokenizer",
            "filter": ["trim"]
        }
    },
    "tokenizer": {
        "semicolon_delimited_tokenizer": {
            "type": "simple_pattern_split",
            "pattern": ";"
        }
    }
}


mappings = {
    "dynamic_templates": [
        {
            "store_as_unindexed_text": {
                "match_mapping_type": "*",
                "mapping": {
                    "type": "text",
                    "index": False
                }
            }
        }
    ],
    "properties": {
        # Always include objectid.
        "objectid": {
            "type": "text",
            "index": False
        }
    }
}


index_settings = {
    "settings": {
        "analysis": analysis,
    },
    "mappings": mappings,
}


def assert_field_def_is_valid(field_def):
    """Assert that the field definition is valid.
    """
    keys = set(field_def)
    missing_keys = VALID_FIELD_DEF_KEYS - keys
    extra_keys = keys - VALID_FIELD_DEF_KEYS
    if missing_keys or extra_keys:
        msg = 'The field definition: {}'.format(field_def)
        if missing_keys:
            msg = '{}\nis missing the required keys: {}'.format(
                msg, missing_keys)
        if extra_keys:
            msg = '{}\nincludes the unexpected keys: {}'.format(
                msg, extra_keys)
        raise AssertionError(msg)

    invalid_bool_value_keys = {
        k for k in BOOL_FIELD_DEF_KEYS
        if field_def[k] not in ('true', 'false')
    }
    if invalid_bool_value_keys:
        raise AssertionError(
            'Expected true/false value found for: {}'
            .format(', '.join(invalid_bool_value_keys))
        )

    if (not field_def['index'] and
        (field_def['facet'] or field_def['multi-valued'])):
        raise AssertionError(
            'Field ({}) has index=false but other index related fields '\
            '(e.g. facet, multi-valued) specified as true'
            .format(field_def['field'])
        )

    if field_def['multi-valued'] and not field_def['facet']:
        raise AssertionError(
            'If field ({}) specifies multi-valued=true, it also need to '\
            'specify multi-valued=true'
            .format(field_def['field'])
        )


def convert_field_def_bools(field_def):
    """Do an in-place conversion of the bool strings to python bool values.
    """
    for k in BOOL_FIELD_DEF_KEYS:
        field_def[k] = field_def[k] == "true"


def AutoMapping(field_def):
    """Return an ES mapping configuration object for the specified field
    definition.
    """
    if field_def['multi-valued']:
        return {
            "type": "text",
            "analyzer": "semicolon_delimited_analyzer",
            "fielddata": True
        }
    if field_def['facet']:
        return {
            "type": "keyword"
        }
    return {
        "type": "text",
        "term_vector": "with_positions"
    }


def main(search_config_fh, output_fh):
    search_config_reader = csv.DictReader(search_config_fh)

    for field_def in search_config_reader:
        assert_field_def_is_valid(field_def)
        convert_field_def_bools(field_def)
        if not field_def['index']:
            continue
        mappings['properties'][field_def['field']] = AutoMapping(field_def)

    output_fh.write(json.dumps(index_settings, indent=2))
    print('Wrote: {}'.format(output_fh.name))


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('search_config_file', type=argparse.FileType('r'))
    parser.add_argument('output_file', type=argparse.FileType('w'))
    args = parser.parse_args()

    main(args.search_config_file, args.output_file)
